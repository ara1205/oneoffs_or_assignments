---
title: "Stat 531 Assignment 1"
author: "Andrew Alexandru"
date: "30065419"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1
* A, Exponential distribution with rate $\lambda$
  + Direct Method
$$
\begin{aligned}
E(X)&=\int_{0}^{\infty }xf(x)\\
&=\int_{0}^{\infty }x\lambda e^{-\lambda x} dx\\
&=\left| -xe^{-\lambda x} \right|^{\infty}_{0}+\int_{0}^{\infty }e^{-\lambda x}dx+0 \\
&=(0-0)+\left| -\frac{1}{\lambda}e^{-\lambda x} \right|^{\infty}_{0} \\
&=0+(0+\frac{1}{\lambda})\\
&=\frac{1}{\lambda}
\end{aligned}
$$
  + Tail Method
$$
\begin{aligned}
E(X) &= 1-F(x)\\ 
&= \int_{0}^{\infty}(1-(1-e^{-\lambda x}))dx\\
&=\int_{0}^{\infty}e^{-\lambda x}\\
u=-\lambda x\\
&=-\frac{1}{\lambda}\int_{0}^{\infty}e^{u}\\
&= \left| -\frac{e^{u}}{\lambda} \right|_{0}^{\infty}\\
&=\left| -\frac{e^{-\lambda x}}{\lambda} \right|_{0}^{\infty} \\
&=0+\frac{1}{\lambda}\\
&=\frac{1}{\lambda}
\end{aligned}
$$
* B, Uniform distribution on $(1,3)$
  + Direct Method
$$
\begin{aligned}
E(X)&=\int_{0}^{\infty }xf(x)\\
&=\int_{1}^{3}\frac{x}{3-1}dx+\int_{0}^{1}x0dx+\int_{3}^{\infty}x0dx \\
&=\frac{1}{3-1}\int_{1}^{3}x\\
&=\frac{4}{2}\\
&=2
\end{aligned}
$$
  + Tail Method
$$
\begin{aligned}
E(X)&=\int_{0}^{\infty}1-F(x)\\
&=\int_{0}^{1}1-0dx+\int_{1}^{3}1-\frac{x-1}{3-1}dx+\int_{3}^{\infty}1-1dx \\
&=1+\frac{3}{2}\int_{1}^{3}1dx-\frac{1}{2}\int_{1}^{3}xdx+0 \\
&=\left| \frac{3x}{2}-\frac{x^{2}}{4} \right|_{1}^{3}+1\\
&=2
\end{aligned}
$$
* C, Pareto distribution with $a=2$
  + Direct Method
$$
\begin{aligned}
E(X)&=\int_{0}^{\infty }xf(x)\\
&=\int_{1}^{\infty}x2x^{-(1+2)}dx+\int_{0}^{1}x0dx\\
&=\int_{1}^{\infty}\frac{2}{x^{2}}dx+0 \\
&=2\int_{1}^{\infty}\frac{1}{x^{2}}\\
&=\left| -\frac{2}{x} \right|_{1}^{\infty}\\
&=2
\end{aligned}
$$
  + Tail Method
$$
\begin{aligned}
E(X)&=\int_{0}^{\infty}1-F(x)\\
&=\int_{1}^{\infty}1-(1-\frac{1}{x}^{2})dx+\int_{0}^{1}1-0dx\\
&=\int_{1}^{\infty}\frac{1}{x^{2}}dx+1 \\
&=\left| -\frac{1}{x} \right|_{1}^{\infty}+1\\
&=2
\end{aligned}
$$

# Question 4
We will be using the direct integration method but with $x-2$ instead of $x$. We will factor out any constants and then integrate by parts to split the integral. Finally we will evaluate it all from $2$ to $\infty$
$$
\begin{aligned}
E(X-2)&=\int_{-\infty}^{\infty}(x-2)f(x)dx\\
&=\int_{2}^{\infty}(x-2)*0.2e^{-0.2x}dx+\int_{-\infty}^{2}(x-2)*0dx \\
&=\int_{2}^{\infty}\frac{(x-2)e^{-\frac{x}{5}}}{5}dx\\
&=\frac{1}{5}\int_{2}^{\infty}(x-2)e^{-\frac{x}{5}}dx \\
&=\frac{1}{5}(\left|-5(x-2)e^{-\frac{x}{5}} \right|_{2}^{\infty}-\int_{2}^{\infty}-5e^{-\frac{x}{5}}) \\
&=\left| \frac{1}{5}(-5(x-2)e^{-\frac{x}{5}}-25e^{-\frac{x}{5}}) \right|_{2}^{\infty} \\
&=\left| -(x+3)e^{-\frac{x}{5}} \right|_{2}^{\infty}\\
&= 0+5e^{-\frac{2}{5}}\\
&=5e^{-\frac{2}{5}}
\end{aligned}
$$
We can see that the expected value is $5e^{-\frac{2}{5}}$ or $3.3516$

# Question 5
* Exponential Memoryless Proof
$$
\begin{aligned}
P(X-y>x|X>y)&=P(X>x+y|X>y) \\
&=\frac{P(X>x+y,X>y)}{P(X>y)}\\
&=\frac{P(X>x+y)}{P(X>y)}\\
&=\frac{1-F(x+y)}{1-F(y)}\\
&=\frac{1-(1-e^{-\lambda(x+y)})}{1-(1-e^{-\lambda y})}\\
&=\frac{e^{-\lambda x}+e^{-\lambda y}}{e^{-\lambda y}}\\
&=e^{-\lambda x}\\
&=P(X>x)
\end{aligned}
$$
* Geometric Memoryless Proof
$$
\begin{aligned}
P(X-m>k|X>m)&=P(X>k+m)\\
&=\frac{P(X>k+m,X>m)}{P(X>m)}\\
&=\frac{P(X>k+m)}{P(X>m)}\\
&=\frac{1-F(k+m)}{1-F(m)}\\
&=\frac{1-(1-(1-p)^{\left\lfloor k+m \right\rfloor})}{1-(1-(1-p)^{\left\lfloor m \right\rfloor})}\\
&=\frac{(1-p)^{\left\lfloor k \right\rfloor}+(1-p)^{\left\lfloor m \right\rfloor}}{(1-p)^{\left\lfloor m \right\rfloor}}\\
&=(1-p)^{\left\lfloor k \right\rfloor}\\
&=P(X>k)
\end{aligned}
$$

# Question 7
$$
\begin{aligned}
E(X|X<0.5)&=\frac{E(X,X<0.5)}{P(X<0.5)}\\
&=\frac{\int_{0}^{0.5}xf(x)dx}{0.5}\\
&=2\int_{0}^{0.5}x\frac{1}{1-0}dx\\
&=2\left| \frac{x^{2}}{2} \right|_{0}^{0.5}\\
&=0.25
\end{aligned}
$$

# Question 9
Because the CDF is a piecewise function we can just take $1-F(x)$ of all section to get the survival function of a uniform distribution.
$$
\begin{aligned}
S(x)&=1-F(x)\\
S(x)&=\begin{Bmatrix}
1-0 & x<2 \\
1-\frac{x-2}{5-2} & x\in [2,5] \\
1-1 & x>5
\end{Bmatrix}\\
\end{aligned}
$$

We can then integrate in this survival function to find the expected value
$$
\begin{aligned}
E(X)&=\int_{0}^{\infty}S(x)\\
&=\int_{0}^{2}1dx+\int_{2}^{5}1-\frac{x-2}{3}dx+\int_{5}^{\infty}0dx\\
&=2+\left| \frac{5x}{3}-\frac{x^{2}}{6} \right|_{2}^{5}+0\\
&=2+\frac{3}{2}\\
&=\frac{7}{2}=3.5
\end{aligned}
$$

# Question 10
To find the inverse we can flip $x$ and $f(x)$ which will be written as $y$ and then solve for it again.
$$
\begin{aligned}
F(x)=y&=1-e^{-\lambda \sqrt{x}}\\
x&=1-e^{-\lambda \sqrt{y)}}\\
log(-\lambda \sqrt{y})&=log(log(1-x))\\
log(\sqrt{y})&=log(log(1-x))-log(-\lambda)\\
log(y)&=2log(log(1-x))-2log(-\lambda)\\
log(y)&=log(\frac{1}{(-\lambda)^{2}})+log(log^2(1-x))\\
log(y)&=log(\frac{log^{2}(1-x)}{\lambda^2})\\
y&=\frac{log^{2}(1-x)}{\lambda^2}=F^{-1}(x)
\end{aligned}
$$
We can then show that $X=F^{-1}(U)$ follows $F(x)$
$$
\begin{aligned}
P(X\le x)&=P(F^{-1}(U)\le x)\\
&=P(U\le F(x))\\
&=F(x)
\end{aligned}
$$
Finnaly we can implemnt the inverse function into an R function to generate variables that follow $F(x)$
```{r,echo=TRUE}
# Setting parameters
set.seed(2022)
n = 10^4
lamda = 4

# Creating function that generates variables
sim.f = function(n,lamda){
  p = runif(n)# Creating random uniform variables
  x = (1/lamda^2)*(log(1-p))^2 # Using the fact that R can run operations on vectors, so no need
  return(x)                                                                          # for loops
}
x = sim.f(n,1) # Calling sim.f function, n amount of times
hist(x)
```

We can see that the seems like a right skewed distribution similar to the Exponential distribution but more extreme due to the $\sqrt{x}$ instead of just $x$. Our sample mean is `r mean(x)` and our sample variance is `r var(x)`.


# Question 12
We will create a function that will simple generate a random uniform variables and then using if statements group bin it in a value.
```{r, echo=TRUE}
set.seed(2022)

# Creating function that generates variables
descr.sim = function(){
  prob = runif(1)
  
  # running if statements based on the probabilities from the distribution
  if(prob <= 0.1){
    return(0)
  }
  else if(prob <= 0.3){
    return(1)
  }
  else if(prob <= 0.5){
    return(2)
  }
  else if(prob <= 0.7){
    return(3)
  }
  else{
    return(4)
  }
}

x=replicate(1000,descr.sim()) # because the function only creates 1 variable at a time, we can use
                                               # the replicate() to run the function over and over

# importing a libary that not only creates a frequency table but also graphs the pdf with columns
library(epiDisplay) 
tab1(x, sort.group = "decreasing", cum.percent = TRUE)                    
```

We can see that the function creates values at around the same proibility as the true pdf. If we were to run with a higher sample size we would get even closer.

```{r, echo=TRUE}
set.seed(2022)
descr.sample = function(n) { #creating function
    sample(x = c(0,1,2,3,4), n, replace = T, prob = c(0.1,0.2, 0.2, 0.2, 0.3)) # using sample and
                     # creating a vector with all the values and another with their probabilities
}
x = descr.sample(1000)
tab1(x, sort.group = "decreasing", cum.percent = TRUE) # as before this command makes the table/graph
```

We can see that the sample method also creates variables with the correct probabilities and seems like both method work equally well.

# Question 13
The expected value of a Beta distribution can be found with the direct $E(X)=\int_{-\infty}^{\infty }xf(x)$ method
$$
\begin{aligned}
E(x)&=\int_{0}^{1} x\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}x^{a-1}(1-x)^{b-1}\\
&=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\int_{0}^{1}x^{a}(1-x)^{b-1}\\
&=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}B(a+1,b)\\
&=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}*\frac{\Gamma(a+1)\Gamma(b)}{\Gamma(a+b+1)}\\
&=\frac{a}{a+b}*\frac{\Gamma(a)\Gamma(b)\Gamma(a+b)}{\Gamma(a)\Gamma(b)\Gamma(a+b)}\\
&=\frac{a}{a+b}
\end{aligned}
$$
We can then find the M value by first finding the pdf of the distribution at $a=3$ and $b=2$
$$
\begin{aligned}
f(x)&=\frac{\Gamma(3+2)}{\Gamma(3)\Gamma(2)}x^{3-1}(1-x)^{2-1}\\
&=\frac{\Gamma(5)}{\Gamma(3)\Gamma(2)}x^{2}(1-x)\\
&=12x^{2}(1-x)
\end{aligned}
$$
and because the we will be testing variables created from the uniform distribution, $g(x)=1$ so $M=\frac{12x^{2}(1-x)}{1}$. We can then run the follow code to find the minimum value for M.

```{r, echo=TRUE}
# Setting parameters
set.seed(2022)
a=3
b=2

f <-  function(x) {12*x^2*(1-x)} # Adding the function for M
m=optimize(f, interval =c(0,1), maximum =TRUE)$objective # trying to find the minimum value for M
```
We can now see that the minimum value for $M$ is `r m` and we can find the probability of acceptance from $p=\frac{1}{M}$ which is `r 1/m`.

Finally we can create a function in R to create Beta variables with the following code.
```{r, echo=TRUE}
set.seed(2022)

beta.sim = function(n,a,b){ # creating function
  f <-  function(x) {dbeta(x, a, b)} # using dbeta() here but its the same as 12*x^2*(1-x)
                                                                    # which we did earlier
  
  m=optimize(f, interval =c(0,1), maximum =TRUE)$objective # we added the entire optimize code here
                           # so that the function would work even if you dont caculate M beforehand
  y <-  runif(n)  
  u <-  runif(n) 
  x = y[u < dbeta(y, a, b)/m ] # same idea here using dbeta()
  return(x)
}
x = beta.sim(10000,3,2) # adding variables here
hist(x)
par(new=TRUE) # this will allow use to basically add another plot right on top and overlap

# creating a plot for the curve, also removing some of the extra labels from the plot
curve((gamma(3+2))/(gamma(3)*gamma(2))*x^(3-1)*(1-x)^(2-1),ylab = "",yaxt='n') 
                                                          
```

We can see now that our function has created variables that do seem to follow the true pdf. We can also see that the sample mean: `r mean(x)` is very close to the real mean: $\frac{3}{3+2}=0.6$.

We can now compare our function to the built in R function.
```{r}
set.seed(2022)
x2 = rbeta(10000,3,2)
hist(x2)
par(new=TRUE)
# for some reason this plot's x-axis is duplicated while earlier it wasn't. I wasn't 
# able to figure out how to fix this or how to add the curve another way, sorry
curve((gamma(3+2))/(gamma(3)*gamma(2))*x^(3-1)*(1-x)^(2-1),ylab = "",yaxt='n') 

```

This is also close to the true pdf, maybe even a bit better. The mean (`r mean(x2)`) is also really close to the true mean.